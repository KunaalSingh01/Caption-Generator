import streamlit as st
import torch
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
import google.generativeai as genai


# ---------------- PAGE CONFIG ----------------
st.set_page_config(
    page_title="AI Caption Generator",
    page_icon="üñºÔ∏è",
    layout="centered"
)

# ---------------- SIDEBAR ----------------
st.sidebar.title("üìå How to use")
st.sidebar.write("""
1Ô∏è‚É£ Upload an image  
2Ô∏è‚É£ Wait for AI to generate caption  
3Ô∏è‚É£ Gemini makes it creative ‚ú®  
4Ô∏è‚É£ Copy & share üéâ  
""")

st.sidebar.markdown("---")
st.sidebar.info("‚ö†Ô∏è This is an AI-generated caption.\nFor creative use only.")

# ---------------- MAIN TITLE ----------------
st.markdown(
    "<h1 style='text-align: center;'>üñºÔ∏è AI Image Caption Generator</h1>",
    unsafe_allow_html=True
)

st.markdown(
    "<p style='text-align: center;'>Turn your images into <b>smart & creative captions</b> using AI ‚ú®</p>",
    unsafe_allow_html=True
)

st.markdown("---")

# ---------------- LOAD GEMINI ----------------
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GEMINI_API_KEY)
model_gemini = genai.GenerativeModel("gemini-1.5-flash")


# ---------------- LOAD BLIP MODEL (FIXED) ----------------
@st.cache_resource
def load_model():
    processor = BlipProcessor.from_pretrained(
        "Salesforce/blip-image-captioning-base"
    )

    model = BlipForConditionalGeneration.from_pretrained(
        "Salesforce/blip-image-captioning-base",
        torch_dtype=torch.float32
    )

    device = torch.device("cpu")  # Streamlit Cloud = CPU only
    model = model.to(device)

    return processor, model, device


processor, model, device = load_model()

# ---------------- GEMINI FUNCTION ----------------
def enhance_caption(raw_caption):
    prompt = f"""
You are an AI assistant.

Task:
1. What I see ‚Üí Describe the image clearly in one simple sentence.
2. Caption for user ‚Üí Write a creative, engaging caption with emojis and hashtags.

Rules:
- Do NOT repeat sentences word by word.
- Keep both parts different in tone and style.

Image description:
{raw_caption}

Output format:

What I see:
<description>

Caption for You:
<creative caption>
"""

    response = model_gemini.generate_content(prompt)
    return response.text.strip()


# ---------------- FILE UPLOAD ----------------
st.subheader("üì§ Upload an Image")

uploaded_image = st.file_uploader(
    "Choose an image (jpg, png, jpeg)",
    type=["jpg", "png", "jpeg"]
)

if uploaded_image:
    image = Image.open(uploaded_image).convert("RGB")

    st.markdown("### üñºÔ∏è Preview")
    st.image(image, use_container_width=True)

    with st.spinner("ü§ñ AI is thinking..."):
        inputs = processor(image, return_tensors="pt")
        inputs = {k: v.to(device) for k, v in inputs.items()}

        output = model.generate(**inputs)
        raw_caption = processor.decode(
            output[0], skip_special_tokens=True
        )

    st.success("‚úÖ Caption generated!")

    st.markdown("### üìù What I See")
    st.code(raw_caption)

    with st.spinner("‚ú® Gemini is adding creativity..."):
        final_caption = enhance_caption(raw_caption)

    st.success("üéâ Done!")

    st.markdown("### üåü Final AI Caption")
    st.text_area(
        "Copy your caption:",
        final_caption,
        height=160
    )

    st.balloons()

else:
    st.info("üëÜ Upload an image to get started!")
